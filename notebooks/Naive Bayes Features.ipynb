{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "stopwords = stopwords.words('english')\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import wordnet_ic\n",
    "brown_ic = wordnet_ic.ic('ic-brown.dat')\n",
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/newtrain.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>why are yawns contagious? when people yawn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>what is trans fat? how to reduce that? i heard...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>roth ira vs 401k? what is the difference betwe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>how many planes fedex has? i heard that it is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>what is the best photo slideshow creation appl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Category                                               Text\n",
       "0         5         why are yawns contagious? when people yawn\n",
       "1         6  what is trans fat? how to reduce that? i heard...\n",
       "2         1  roth ira vs 401k? what is the difference betwe...\n",
       "3         1  how many planes fedex has? i heard that it is ...\n",
       "4         2  what is the best photo slideshow creation appl..."
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "random_index = np.random.permutation(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_shuffled = df.ix[random_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>how do i run a ruby program on winxp (i have r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>what do you call the 4-stringed hawaiian instr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>when will undertaker of wwe ..........will rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>do space heaters really save money? instead of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>red hot chilli peppers vs foo fighters? whom d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Category                                               Text\n",
       "0         2  how do i run a ruby program on winxp (i have r...\n",
       "1         5  what do you call the 4-stringed hawaiian instr...\n",
       "2         3  when will undertaker of wwe ..........will rea...\n",
       "3         1  do space heaters really save money? instead of...\n",
       "4         3  red hot chilli peppers vs foo fighters? whom d..."
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_shuffled.reset_index(drop=True, inplace=True)\n",
    "df_shuffled[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rows, columns = df_shuffled.shape\n",
    "train_size = round(rows*.8)\n",
    "dev_size   = round(rows*.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train = df_shuffled.loc[:train_size]\n",
    "df_dev = df_shuffled.loc[train_size:dev_size+train_size].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten_words(list1d, get_unique=False):\n",
    "    qa = [s.split() for s in list1d]\n",
    "    if get_unique:\n",
    "        return sorted(list(set([w for sent in qa for w in sent])))\n",
    "    else:\n",
    "        return [w for sent in qa for w in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['why',\n",
       " 'are',\n",
       " 'yawns',\n",
       " 'contagious',\n",
       " 'when',\n",
       " 'people',\n",
       " 'yawn',\n",
       " 'what',\n",
       " 'is',\n",
       " 'trans']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = flatten_words(df.text_clean.values)\n",
    "words[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def unigram_feature(x, unigrams):\n",
    "    word_list = x.lower().split(\" \")\n",
    "    count = 0\n",
    "    for unigram in unigrams:\n",
    "        count += word_list.count(unigram)\n",
    "    return count\n",
    "def numeric_feature(x):\n",
    "    return sum(w.isnumeric() for w in x)\n",
    "def similarity_feature(x, word):\n",
    "    similarity = 0\n",
    "    for w in x:\n",
    "        for s in wn.synsets(w, pos=wn.NOUN):\n",
    "            similarity = max(similarity, word.wup_similarity(s)) \n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_ql = df.copy()\n",
    "df_ql = df_ql[['Category', 'text_clean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_ql['all_questions'] = df_ql.apply(lambda row:\n",
    "                                     df.groupby('Category').get_group(row['Category'])['text_clean'].tolist(),\n",
    "                                     axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_ql.drop_duplicates(subset='Category', inplace=True)\n",
    "df_ql.sort(columns='Category', inplace=True)\n",
    "df_ql.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_norm_words(collection):\n",
    "    pattern = r'''(?x)    \n",
    "         ([A-Z]\\.)+        \n",
    "       | \\w+        \n",
    "       | \\$?\\d+(\\.\\d+)?%?  \n",
    "       | \\.\\.\\.            \n",
    "     '''\n",
    "    tokens = nltk.regexp_tokenize(collection, pattern)\n",
    "    collection_words = [w.lower() for w in tokens if w.lower() not in stopwords and len(w) > 3 ]\n",
    "    return collection_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_ql.all_questions[0]\n",
    "category1_questions = [q for q in df_ql.all_questions[0]]\n",
    "category2_questions = [q for q in df_ql.all_questions[1]]\n",
    "category3_questions = [q for q in df_ql.all_questions[2]]\n",
    "category4_questions = [q for q in df_ql.all_questions[3]]\n",
    "category5_questions = [q for q in df_ql.all_questions[4]]\n",
    "category6_questions = [q for q in df_ql.all_questions[5]]\n",
    "category7_questions = [q for q in df_ql.all_questions[6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "category1_words = []\n",
    "for i in range(len(category1_questions)):\n",
    "    category1_words += get_norm_words(category1_questions[i])\n",
    "category2_words = []\n",
    "for i in range(len(category2_questions)):\n",
    "    category2_words += get_norm_words(category2_questions[i])\n",
    "category3_words = []\n",
    "for i in range(len(category3_questions)):\n",
    "    category3_words += get_norm_words(category1_questions[i])\n",
    "category4_words = []\n",
    "for i in range(len(category4_questions)):\n",
    "    category4_words += get_norm_words(category4_questions[i])\n",
    "category5_words = []\n",
    "for i in range(len(category5_questions)):\n",
    "    category5_words += get_norm_words(category5_questions[i])\n",
    "category6_words = []\n",
    "for i in range(len(category6_questions)):\n",
    "    category6_words += get_norm_words(category6_questions[i])\n",
    "category7_words = []\n",
    "for i in range(len(category7_questions)):\n",
    "    category7_words += get_norm_words(category7_questions[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def norm_unigram_fd(collection_words):\n",
    "    fd_collection = nltk.FreqDist(collection_words) \n",
    "    fd = nltk.FreqDist(words) \n",
    "    fd_norm = fd_collection.copy()\n",
    "    for w in fd_collection.keys():\n",
    "        fd_norm[w] = (float(fd_collection[w]) / (1+ fd[w]))\n",
    "    return fd_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fd1 = norm_unigram_fd(category1_words)\n",
    "fd2 = norm_unigram_fd(category2_words)\n",
    "fd3 = norm_unigram_fd(category3_words)\n",
    "fd4 = norm_unigram_fd(category4_words)\n",
    "fd5 = norm_unigram_fd(category5_words)\n",
    "fd6 = norm_unigram_fd(category6_words)\n",
    "fd7 = norm_unigram_fd(category7_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dipole', 'plane', 'bear', 'light', 'theory']"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finance = wn.synset('finance.n.01')\n",
    "internet = wn.synset('internet.n.01')\n",
    "entertainment = wn.synset('entertainment.n.01')\n",
    "music = wn.synset('music.n.01')\n",
    "relationship = wn.synset('relationship.n.01')\n",
    "family = wn.synset('family.n.01')\n",
    "education = wn.synset('education.n.01')\n",
    "health = wn.synset('health.n.01')\n",
    "science = wn.synset('science.n.01')\n",
    "math = wn.synset('mathematics.n.01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "amt = 500\n",
    "train_fd1_feature = df_train['Text'].apply(lambda x: unigram_feature(x, ([w[0] for w in fd1.most_common(amt)])))\n",
    "train_fd2_feature = df_train['Text'].apply(lambda x: unigram_feature(x, ([w[0] for w in fd2.most_common(amt)])))\n",
    "train_fd3_feature = df_train['Text'].apply(lambda x: unigram_feature(x, ([w[0] for w in fd3.most_common(amt)])))\n",
    "train_fd4_feature = df_train['Text'].apply(lambda x: unigram_feature(x, ([w[0] for w in fd4.most_common(amt)])))\n",
    "train_fd5_feature = df_train['Text'].apply(lambda x: unigram_feature(x, ([w[0] for w in fd5.most_common(amt)])))\n",
    "train_fd6_feature = df_train['Text'].apply(lambda x: unigram_feature(x, ([w[0] for w in fd6.most_common(amt)])))\n",
    "train_fd7_feature = df_train['Text'].apply(lambda x: unigram_feature(x, ([w[0] for w in fd7.most_common(amt)])))\n",
    "\n",
    "train_what_feature = df_train['Text'].apply(lambda x: unigram_feature(x, (\"what\")))\n",
    "train_who_feature = df_train['Text'].apply(lambda x: unigram_feature(x, (\"who\")))\n",
    "train_why_feature = df_train['Text'].apply(lambda x: unigram_feature(x, (\"why\")))\n",
    "train_how_feature = df_train['Text'].apply(lambda x: unigram_feature(x, (\"how\")))\n",
    "\n",
    "# train_finance_sim_feature = df_train['Text'].apply(lambda x: similarity_feature(x, finance))\n",
    "# train_internet_sim_feature = df_train['Text'].apply(lambda x: similarity_feature(x, internet))\n",
    "# train_entertainment_sim_feature = df_train['Text'].apply(lambda x: similarity_feature(x, entertainment))\n",
    "# train_music_sim_feature = df_train['Text'].apply(lambda x: similarity_feature(x, music))\n",
    "# train_relationship_sim_feature = df_train['Text'].apply(lambda x: similarity_feature(x, relationship))\n",
    "# train_family_sim_feature = df_train['Text'].apply(lambda x: similarity_feature(x, family))\n",
    "# train_education_sim_feature = df_train['Text'].apply(lambda x: similarity_feature(x, education))\n",
    "# train_health_sim_feature = df_train['Text'].apply(lambda x: similarity_feature(x, health))\n",
    "# train_science_sim_feature = df_train['Text'].apply(lambda x: similarity_feature(x, science))\n",
    "# train_math_sim_feature = df_train['Text'].apply(lambda x: similarity_feature(x, math))\n",
    "\n",
    "train_numeric_feature = df_train['Text'].apply(lambda x: numeric_feature(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train_features = pd.DataFrame({'fd1': train_fd1_feature, \n",
    "                                  'fd2': train_fd2_feature, \n",
    "                                  'fd3': train_fd3_feature,\n",
    "                                  'fd4': train_fd4_feature, \n",
    "                                  'fd5': train_fd5_feature, \n",
    "                                  'fd6': train_fd6_feature,\n",
    "                                  'fd7': train_fd7_feature,\n",
    "                                  'what': train_what_feature, \n",
    "                                  'who': train_who_feature, \n",
    "                                  'why': train_why_feature,\n",
    "                                  'how': train_how_feature,\n",
    "#                                    'finance': train_finance_sim_feature, \n",
    "#                                   'internet': train_internet_sim_feature,\n",
    "#                                   'entertainment': train_entertainment_sim_feature, \n",
    "#                                   'music':train_music_sim_feature, \n",
    "#                                   'relationship': train_relationship_sim_feature, \n",
    "#                                   'family': train_family_sim_feature,\n",
    "#                                   'education': train_education_sim_feature, \n",
    "#                                   'health':train_health_sim_feature,\n",
    "#                                   'science': train_science_sim_feature, \n",
    "#                                   'math':train_math_sim_feature,\n",
    "                                 'numbers': train_numeric_feature})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dev_fd1_feature = df_dev['Text'].apply(lambda x: unigram_feature(x, ([w[0] for w in fd1.most_common(amt)])))\n",
    "dev_fd2_feature = df_dev['Text'].apply(lambda x: unigram_feature(x, ([w[0] for w in fd2.most_common(amt)])))\n",
    "dev_fd3_feature = df_dev['Text'].apply(lambda x: unigram_feature(x, ([w[0] for w in fd3.most_common(amt)])))\n",
    "dev_fd4_feature = df_dev['Text'].apply(lambda x: unigram_feature(x, ([w[0] for w in fd4.most_common(amt)])))\n",
    "dev_fd5_feature = df_dev['Text'].apply(lambda x: unigram_feature(x, ([w[0] for w in fd5.most_common(amt)])))\n",
    "dev_fd6_feature = df_dev['Text'].apply(lambda x: unigram_feature(x, ([w[0] for w in fd6.most_common(amt)])))\n",
    "dev_fd7_feature = df_dev['Text'].apply(lambda x: unigram_feature(x, ([w[0] for w in fd7.most_common(amt)])))\n",
    "dev_what_feature = df_dev['Text'].apply(lambda x: unigram_feature(x, (\"what\")))\n",
    "dev_who_feature = df_dev['Text'].apply(lambda x: unigram_feature(x, (\"who\")))\n",
    "dev_why_feature = df_dev['Text'].apply(lambda x: unigram_feature(x, (\"why\")))\n",
    "dev_how_feature = df_dev['Text'].apply(lambda x: unigram_feature(x, (\"how\")))\n",
    "dev_numeric_feature = df_dev['Text'].apply(lambda x: numeric_feature(x))\n",
    "# dev_finance_sim_feature = df_dev['Text'].apply(lambda x: similarity_feature(x, finance))\n",
    "# dev_internet_sim_feature = df_dev['Text'].apply(lambda x: similarity_feature(x, internet))\n",
    "# dev_entertainment_sim_feature = df_dev['Text'].apply(lambda x: similarity_feature(x, entertainment))\n",
    "# dev_music_sim_feature = df_dev['Text'].apply(lambda x: similarity_feature(x, music))\n",
    "# dev_relationship_sim_feature = df_dev['Text'].apply(lambda x: similarity_feature(x, relationship))\n",
    "# dev_family_sim_feature = df_dev['Text'].apply(lambda x: similarity_feature(x, family))\n",
    "# dev_education_sim_feature = df_dev['Text'].apply(lambda x: similarity_feature(x, education))\n",
    "# dev_health_sim_feature = df_dev['Text'].apply(lambda x: similarity_feature(x, health))\n",
    "# dev_science_sim_feature = df_dev['Text'].apply(lambda x: similarity_feature(x, science))\n",
    "# dev_math_sim_feature = df_dev['Text'].apply(lambda x: similarity_feature(x, math))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_dev_features = pd.DataFrame({'fd1': dev_fd1_feature, \n",
    "                                  'fd2': dev_fd2_feature, \n",
    "                                  'fd3': dev_fd3_feature,\n",
    "                                  'fd4': dev_fd4_feature, \n",
    "                                  'fd5': dev_fd5_feature, \n",
    "                                  'fd6': dev_fd6_feature,\n",
    "                                  'fd7': dev_fd7_feature,\n",
    "                                  'what': dev_what_feature, \n",
    "                                  'who': dev_who_feature, \n",
    "                                  'why': dev_why_feature,\n",
    "                                  'how': dev_how_feature,\n",
    "#                                  'finance': dev_finance_sim_feature, \n",
    "#                                   'internet': dev_internet_sim_feature,\n",
    "#                                   'entertainment': dev_entertainment_sim_feature, \n",
    "#                                   'music': dev_music_sim_feature, \n",
    "#                                   'relationship': dev_relationship_sim_feature, \n",
    "#                                   'family': dev_family_sim_feature,\n",
    "#                                   'education': dev_education_sim_feature, \n",
    "#                                   'health': dev_health_sim_feature,\n",
    "#                                   'science': dev_science_sim_feature, \n",
    "#                                   'math': dev_math_sim_feature,\n",
    "                                  'numbers': dev_numeric_feature})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb_model = nb.fit(df_train_features, df_train.Category)\n",
    "nb_predictions = nb_model.predict(df_dev_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66666666666666663"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(df_dev.Category, nb_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.57      0.82      0.67       154\n",
      "          2       0.88      0.72      0.79        88\n",
      "          3       0.26      0.13      0.17        78\n",
      "          4       0.71      0.70      0.70        73\n",
      "          5       0.73      0.70      0.71        53\n",
      "          6       0.85      0.79      0.81        42\n",
      "          7       0.89      0.77      0.82        52\n",
      "\n",
      "avg / total       0.66      0.67      0.65       540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_labels = np.sort(df_train.Category.unique())\n",
    "class_labels = [str(l) for l in class_labels]\n",
    "\n",
    "print(classification_report(df_dev.Category, nb_predictions, target_names=class_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_set = pd.read_csv('../data/newtest.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_fd1_feature = test_set['Text'].apply(lambda x: unigram_feature(x, ([w[0] for w in fd1.most_common(amt)])))\n",
    "test_fd2_feature = test_set['Text'].apply(lambda x: unigram_feature(x, ([w[0] for w in fd2.most_common(amt)])))\n",
    "test_fd3_feature = test_set['Text'].apply(lambda x: unigram_feature(x, ([w[0] for w in fd3.most_common(amt)])))\n",
    "test_fd4_feature = test_set['Text'].apply(lambda x: unigram_feature(x, ([w[0] for w in fd4.most_common(amt)])))\n",
    "test_fd5_feature = test_set['Text'].apply(lambda x: unigram_feature(x, ([w[0] for w in fd5.most_common(amt)])))\n",
    "test_fd6_feature = test_set['Text'].apply(lambda x: unigram_feature(x, ([w[0] for w in fd6.most_common(amt)])))\n",
    "test_fd7_feature = test_set['Text'].apply(lambda x: unigram_feature(x, ([w[0] for w in fd7.most_common(amt)])))\n",
    "test_what_feature = test_set['Text'].apply(lambda x: unigram_feature(x, (\"what\")))\n",
    "test_who_feature = test_set['Text'].apply(lambda x: unigram_feature(x, (\"who\")))\n",
    "test_why_feature = test_set['Text'].apply(lambda x: unigram_feature(x, (\"why\")))\n",
    "test_how_feature = test_set['Text'].apply(lambda x: unigram_feature(x, (\"how\")))\n",
    "test_numeric_feature = test_set['Text'].apply(lambda x: numeric_feature(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test_features = pd.DataFrame({'fd1': test_fd1_feature, \n",
    "                                  'fd2': test_fd2_feature, \n",
    "                                  'fd3': test_fd3_feature,\n",
    "                                  'fd4': test_fd4_feature, \n",
    "                                  'fd5': test_fd5_feature, \n",
    "                                  'fd6': test_fd6_feature,\n",
    "                                  'fd7': test_fd7_feature,\n",
    "                                  'what': test_what_feature, \n",
    "                                  'who': test_who_feature, \n",
    "                                  'why': test_why_feature,\n",
    "                                  'how': test_how_feature,\n",
    "                                  'numbers': test_numeric_feature})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_predictions = nb_model.predict(df_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(nb_predictions)\n",
    "len(test_set)\n",
    "test_set[\"category\"] = nb_predictions[test_set.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output = test_set[['Id', 'category']]\n",
    "output.to_csv('../data/solution.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.3.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
