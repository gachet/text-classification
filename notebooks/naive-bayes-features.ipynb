{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "stopwords = stopwords.words('english')\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import wordnet_ic\n",
    "brown_ic = wordnet_ic.ic('ic-brown.dat')\n",
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/newtrain.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>why are yawns contagious? when people yawn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>what is trans fat? how to reduce that? i heard...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>roth ira vs 401k? what is the difference betwe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>how many planes fedex has? i heard that it is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>what is the best photo slideshow creation appl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Category                                               Text\n",
       "0         5         why are yawns contagious? when people yawn\n",
       "1         6  what is trans fat? how to reduce that? i heard...\n",
       "2         1  roth ira vs 401k? what is the difference betwe...\n",
       "3         1  how many planes fedex has? i heard that it is ...\n",
       "4         2  what is the best photo slideshow creation appl..."
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "random_index = np.random.permutation(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_shuffled = df.ix[random_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>what does xoxo stand for?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>what was james bond's wife's name? i seem to b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>how to solve magic cube ? could please tell me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>what is tia carrere's nationality?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>what is the deepest trough in the world?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Category                                               Text\n",
       "0         5                          what does xoxo stand for?\n",
       "1         5  what was james bond's wife's name? i seem to b...\n",
       "2         7  how to solve magic cube ? could please tell me...\n",
       "3         3                 what is tia carrere's nationality?\n",
       "4         7           what is the deepest trough in the world?"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_shuffled.reset_index(drop=True, inplace=True)\n",
    "df_shuffled[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rows, columns = df_shuffled.shape\n",
    "train_size = round(rows*.8)\n",
    "dev_size   = round(rows*.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train = df_shuffled.loc[:train_size]\n",
    "df_dev = df_shuffled.loc[train_size:dev_size+train_size].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten_words(list1d, get_unique=False):\n",
    "    qa = [s.split() for s in list1d]\n",
    "    if get_unique:\n",
    "        return sorted(list(set([w for sent in qa for w in sent])))\n",
    "    else:\n",
    "        return [w for sent in qa for w in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['text_clean'] = df['Text'].apply(lambda x: re.sub('[^A-Za-z0-9]+', ' ', x.lower()))\\\n",
    "                             .apply(lambda x: re.sub('\\s+', ' ', x).strip())\n",
    "words = flatten_words(df.text_clean.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def unigram_feature(x, unigrams):\n",
    "    word_list = x.lower().split(\" \")\n",
    "    count = 0\n",
    "    for unigram in unigrams:\n",
    "        count += word_list.count(unigram)\n",
    "    return count\n",
    "def numeric_feature(x):\n",
    "    return sum(w.isnumeric() for w in x)\n",
    "def similarity_feature(x, word):\n",
    "    word_list = x.lower().split(\" \")\n",
    "    similarity = 0\n",
    "    for w in word_list:\n",
    "        for s in wn.synsets(w, pos=wn.NOUN):\n",
    "            similarity = max(similarity, word.wup_similarity(s)) \n",
    "    return similarity\n",
    "def length_feature(x):\n",
    "    return len(x)\n",
    "def pos_feature(x, pos):\n",
    "    word_list = x.lower().split(\" \")\n",
    "    t = nltk.pos_tag(word_list)\n",
    "    count = 0\n",
    "    for w in t:\n",
    "        if w[1] == pos:\n",
    "                count+=1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_ql = df.copy()\n",
    "df_ql = df_ql[['Category', 'text_clean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_ql['all_questions'] = df_ql.apply(lambda row:\n",
    "                                     df.groupby('Category').get_group(row['Category'])['text_clean'].tolist(),\n",
    "                                     axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_ql.drop_duplicates(subset='Category', inplace=True)\n",
    "df_ql.sort(columns='Category', inplace=True)\n",
    "df_ql.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_norm_words(collection):\n",
    "    pattern = r'''(?x)    \n",
    "         ([A-Z]\\.)+        \n",
    "       | \\w+        \n",
    "       | \\$?\\d+(\\.\\d+)?%?  \n",
    "       | \\.\\.\\.            \n",
    "     '''\n",
    "    tokens = nltk.regexp_tokenize(collection, pattern)\n",
    "    collection_words = [w.lower() for w in tokens if w.lower() not in stopwords and len(w) > 3 ]\n",
    "    return collection_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_ql.all_questions[0]\n",
    "category1_questions = [q for q in df_ql.all_questions[0]]\n",
    "category2_questions = [q for q in df_ql.all_questions[1]]\n",
    "category3_questions = [q for q in df_ql.all_questions[2]]\n",
    "category4_questions = [q for q in df_ql.all_questions[3]]\n",
    "category5_questions = [q for q in df_ql.all_questions[4]]\n",
    "category6_questions = [q for q in df_ql.all_questions[5]]\n",
    "category7_questions = [q for q in df_ql.all_questions[6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "category1_words = []\n",
    "for i in range(len(category1_questions)):\n",
    "    category1_words += get_norm_words(category1_questions[i])\n",
    "category2_words = []\n",
    "for i in range(len(category2_questions)):\n",
    "    category2_words += get_norm_words(category2_questions[i])\n",
    "category3_words = []\n",
    "for i in range(len(category3_questions)):\n",
    "    category3_words += get_norm_words(category1_questions[i])\n",
    "category4_words = []\n",
    "for i in range(len(category4_questions)):\n",
    "    category4_words += get_norm_words(category4_questions[i])\n",
    "category5_words = []\n",
    "for i in range(len(category5_questions)):\n",
    "    category5_words += get_norm_words(category5_questions[i])\n",
    "category6_words = []\n",
    "for i in range(len(category6_questions)):\n",
    "    category6_words += get_norm_words(category6_questions[i])\n",
    "category7_words = []\n",
    "for i in range(len(category7_questions)):\n",
    "    category7_words += get_norm_words(category7_questions[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def norm_unigram_fd(collection_words):\n",
    "    fd_collection = nltk.FreqDist(collection_words) \n",
    "    fd = nltk.FreqDist(words) \n",
    "    fd_norm = fd_collection.copy()\n",
    "    for w in fd_collection.keys():\n",
    "        fd_norm[w] = (float(fd_collection[w]) / (1+ fd[w]))\n",
    "    return fd_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fd1 = norm_unigram_fd(category1_words)\n",
    "fd2 = norm_unigram_fd(category2_words)\n",
    "fd3 = norm_unigram_fd(category3_words)\n",
    "fd4 = norm_unigram_fd(category4_words)\n",
    "fd5 = norm_unigram_fd(category5_words)\n",
    "fd6 = norm_unigram_fd(category6_words)\n",
    "fd7 = norm_unigram_fd(category7_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "finance = wn.synset('finance.n.01')\n",
    "internet = wn.synset('internet.n.01')\n",
    "entertainment = wn.synset('entertainment.n.01')\n",
    "music = wn.synset('music.n.01')\n",
    "relationship = wn.synset('relationship.n.01')\n",
    "family = wn.synset('family.n.01')\n",
    "education = wn.synset('education.n.01')\n",
    "health = wn.synset('health.n.01')\n",
    "science = wn.synset('science.n.01')\n",
    "math = wn.synset('mathematics.n.01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "amt = 500\n",
    "train_fd1_feature = df_train['Text'].apply(lambda x: unigram_feature(x, ([w[0] for w in fd1.most_common(amt)])))\n",
    "train_fd2_feature = df_train['Text'].apply(lambda x: unigram_feature(x, ([w[0] for w in fd2.most_common(amt)])))\n",
    "train_fd3_feature = df_train['Text'].apply(lambda x: unigram_feature(x, ([w[0] for w in fd3.most_common(amt)])))\n",
    "train_fd4_feature = df_train['Text'].apply(lambda x: unigram_feature(x, ([w[0] for w in fd4.most_common(amt)])))\n",
    "train_fd5_feature = df_train['Text'].apply(lambda x: unigram_feature(x, ([w[0] for w in fd5.most_common(amt)])))\n",
    "train_fd6_feature = df_train['Text'].apply(lambda x: unigram_feature(x, ([w[0] for w in fd6.most_common(amt)])))\n",
    "train_fd7_feature = df_train['Text'].apply(lambda x: unigram_feature(x, ([w[0] for w in fd7.most_common(amt)])))\n",
    "\n",
    "train_what_feature = df_train['Text'].apply(lambda x: unigram_feature(x, (\"what\")))\n",
    "train_who_feature = df_train['Text'].apply(lambda x: unigram_feature(x, (\"who\")))\n",
    "train_why_feature = df_train['Text'].apply(lambda x: unigram_feature(x, (\"why\")))\n",
    "train_how_feature = df_train['Text'].apply(lambda x: unigram_feature(x, (\"how\")))\n",
    "\n",
    "train_finance_sim_feature = df_train['Text'].apply(lambda x: similarity_feature(x, finance))\n",
    "train_internet_sim_feature = df_train['Text'].apply(lambda x: similarity_feature(x, internet))\n",
    "train_entertainment_sim_feature = df_train['Text'].apply(lambda x: similarity_feature(x, entertainment))\n",
    "train_music_sim_feature = df_train['Text'].apply(lambda x: similarity_feature(x, music))\n",
    "train_relationship_sim_feature = df_train['Text'].apply(lambda x: similarity_feature(x, relationship))\n",
    "train_family_sim_feature = df_train['Text'].apply(lambda x: similarity_feature(x, family))\n",
    "train_education_sim_feature = df_train['Text'].apply(lambda x: similarity_feature(x, education))\n",
    "train_health_sim_feature = df_train['Text'].apply(lambda x: similarity_feature(x, health))\n",
    "train_science_sim_feature = df_train['Text'].apply(lambda x: similarity_feature(x, science))\n",
    "train_math_sim_feature = df_train['Text'].apply(lambda x: similarity_feature(x, math))\n",
    "\n",
    "train_posV_feature = df_train['Text'].apply(lambda x: pos_feature(x, \"VB\"))\n",
    "train_posJJ_feature = df_train['Text'].apply(lambda x: pos_feature(x, \"JJ\"))\n",
    "\n",
    "train_length_feature = df_train['Text'].apply(lambda x: length_feature(x))\n",
    "train_numeric_feature = df_train['Text'].apply(lambda x: numeric_feature(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train_features = pd.DataFrame({'fd1': train_fd1_feature, \n",
    "                                  'fd2': train_fd2_feature, \n",
    "                                  'fd3': train_fd3_feature,\n",
    "                                  'fd4': train_fd4_feature, \n",
    "                                  'fd5': train_fd5_feature, \n",
    "                                  'fd6': train_fd6_feature,\n",
    "                                  'fd7': train_fd7_feature,\n",
    "                                  'what': train_what_feature, \n",
    "                                  'who': train_who_feature, \n",
    "                                  'why': train_why_feature,\n",
    "                                  'how': train_how_feature,\n",
    "#                                    'finance': train_finance_sim_feature, \n",
    "#                                   'internet': train_internet_sim_feature,\n",
    "#                                   'entertainment': train_entertainment_sim_feature, \n",
    "#                                   'music':train_music_sim_feature, \n",
    "#                                   'relationship': train_relationship_sim_feature, \n",
    "#                                   'family': train_family_sim_feature,\n",
    "#                                   'education': train_education_sim_feature, \n",
    "#                                   'health':train_health_sim_feature,\n",
    "#                                   'science': train_science_sim_feature, \n",
    "#                                   'math':train_math_sim_feature,\n",
    "                                 'numbers': train_numeric_feature,\n",
    "                                 'posV': train_posV_feature,\n",
    "                                #'posJJ': train_posJJ_feature,\n",
    "                                 'length': train_length_feature})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dev_fd1_feature = df_dev['Text'].apply(lambda x: unigram_feature(x, ([w[0] for w in fd1.most_common(amt)])))\n",
    "dev_fd2_feature = df_dev['Text'].apply(lambda x: unigram_feature(x, ([w[0] for w in fd2.most_common(amt)])))\n",
    "dev_fd3_feature = df_dev['Text'].apply(lambda x: unigram_feature(x, ([w[0] for w in fd3.most_common(amt)])))\n",
    "dev_fd4_feature = df_dev['Text'].apply(lambda x: unigram_feature(x, ([w[0] for w in fd4.most_common(amt)])))\n",
    "dev_fd5_feature = df_dev['Text'].apply(lambda x: unigram_feature(x, ([w[0] for w in fd5.most_common(amt)])))\n",
    "dev_fd6_feature = df_dev['Text'].apply(lambda x: unigram_feature(x, ([w[0] for w in fd6.most_common(amt)])))\n",
    "dev_fd7_feature = df_dev['Text'].apply(lambda x: unigram_feature(x, ([w[0] for w in fd7.most_common(amt)])))\n",
    "dev_what_feature = df_dev['Text'].apply(lambda x: unigram_feature(x, (\"what\")))\n",
    "dev_who_feature = df_dev['Text'].apply(lambda x: unigram_feature(x, (\"who\")))\n",
    "dev_why_feature = df_dev['Text'].apply(lambda x: unigram_feature(x, (\"why\")))\n",
    "dev_how_feature = df_dev['Text'].apply(lambda x: unigram_feature(x, (\"how\")))\n",
    "dev_numeric_feature = df_dev['Text'].apply(lambda x: numeric_feature(x))\n",
    "dev_length_feature = df_dev['Text'].apply(lambda x: length_feature(x))\n",
    "dev_finance_sim_feature = df_dev['Text'].apply(lambda x: similarity_feature(x, finance))\n",
    "dev_internet_sim_feature = df_dev['Text'].apply(lambda x: similarity_feature(x, internet))\n",
    "dev_entertainment_sim_feature = df_dev['Text'].apply(lambda x: similarity_feature(x, entertainment))\n",
    "dev_music_sim_feature = df_dev['Text'].apply(lambda x: similarity_feature(x, music))\n",
    "dev_relationship_sim_feature = df_dev['Text'].apply(lambda x: similarity_feature(x, relationship))\n",
    "dev_family_sim_feature = df_dev['Text'].apply(lambda x: similarity_feature(x, family))\n",
    "dev_education_sim_feature = df_dev['Text'].apply(lambda x: similarity_feature(x, education))\n",
    "dev_health_sim_feature = df_dev['Text'].apply(lambda x: similarity_feature(x, health))\n",
    "dev_science_sim_feature = df_dev['Text'].apply(lambda x: similarity_feature(x, science))\n",
    "dev_math_sim_feature = df_dev['Text'].apply(lambda x: similarity_feature(x, math))\n",
    "dev_posV_feature = df_dev['Text'].apply(lambda x: pos_feature(x, \"VB\"))\n",
    "dev_posJJ_feature = df_dev['Text'].apply(lambda x: pos_feature(x, \"JJ\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_dev_features = pd.DataFrame({'fd1': dev_fd1_feature, \n",
    "                                  'fd2': dev_fd2_feature, \n",
    "                                  'fd3': dev_fd3_feature,\n",
    "                                  'fd4': dev_fd4_feature, \n",
    "                                  'fd5': dev_fd5_feature, \n",
    "                                  'fd6': dev_fd6_feature,\n",
    "                                  'fd7': dev_fd7_feature,\n",
    "                                  'what': dev_what_feature, \n",
    "                                  'who': dev_who_feature, \n",
    "                                  'why': dev_why_feature,\n",
    "                                  'how': dev_how_feature,\n",
    "#                                  'finance': dev_finance_sim_feature, \n",
    "#                                   'internet': dev_internet_sim_feature,\n",
    "#                                   'entertainment': dev_entertainment_sim_feature, \n",
    "#                                   'music': dev_music_sim_feature, \n",
    "#                                   'relationship': dev_relationship_sim_feature, \n",
    "#                                   'family': dev_family_sim_feature,\n",
    "#                                   'education': dev_education_sim_feature, \n",
    "#                                   'health': dev_health_sim_feature,\n",
    "#                                   'science': dev_science_sim_feature, \n",
    "#                                   'math': dev_math_sim_feature,\n",
    "                                'length': dev_length_feature,\n",
    "                                 'posV': dev_posV_feature,\n",
    "                                #'posJJ': dev_posJJ_feature,\n",
    "                                  'numbers': dev_numeric_feature})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb_model = nb.fit(df_train_features, df_train.Category)\n",
    "nb_predictions = nb_model.predict(df_dev_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71481481481481479"
      ]
     },
     "execution_count": 570,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(df_dev.Category, nb_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.66      0.70       158\n",
      "          2       0.76      0.74      0.75        76\n",
      "          3       0.44      0.60      0.51        73\n",
      "          4       0.69      0.71      0.70        70\n",
      "          5       0.84      0.87      0.85        54\n",
      "          6       0.84      0.84      0.84        57\n",
      "          7       0.86      0.69      0.77        52\n",
      "\n",
      "avg / total       0.73      0.71      0.72       540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_labels = np.sort(df_train.Category.unique())\n",
    "class_labels = [str(l) for l in class_labels]\n",
    "\n",
    "print(classification_report(df_dev.Category, nb_predictions, target_names=class_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_set = pd.read_csv('../data/newtest.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_fd1_feature = test_set['Text'].apply(lambda x: unigram_feature(x, ([w[0] for w in fd1.most_common(amt)])))\n",
    "test_fd2_feature = test_set['Text'].apply(lambda x: unigram_feature(x, ([w[0] for w in fd2.most_common(amt)])))\n",
    "test_fd3_feature = test_set['Text'].apply(lambda x: unigram_feature(x, ([w[0] for w in fd3.most_common(amt)])))\n",
    "test_fd4_feature = test_set['Text'].apply(lambda x: unigram_feature(x, ([w[0] for w in fd4.most_common(amt)])))\n",
    "test_fd5_feature = test_set['Text'].apply(lambda x: unigram_feature(x, ([w[0] for w in fd5.most_common(amt)])))\n",
    "test_fd6_feature = test_set['Text'].apply(lambda x: unigram_feature(x, ([w[0] for w in fd6.most_common(amt)])))\n",
    "test_fd7_feature = test_set['Text'].apply(lambda x: unigram_feature(x, ([w[0] for w in fd7.most_common(amt)])))\n",
    "test_what_feature = test_set['Text'].apply(lambda x: unigram_feature(x, (\"what\")))\n",
    "test_who_feature = test_set['Text'].apply(lambda x: unigram_feature(x, (\"who\")))\n",
    "test_why_feature = test_set['Text'].apply(lambda x: unigram_feature(x, (\"why\")))\n",
    "test_how_feature = test_set['Text'].apply(lambda x: unigram_feature(x, (\"how\")))\n",
    "test_numeric_feature = test_set['Text'].apply(lambda x: numeric_feature(x))\n",
    "test_pos_feature = test_set['Text'].apply(lambda x: pos_feature(x, \"VB\"))\n",
    "test_length_feature = test_set['Text'].apply(lambda x: length_feature(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test_features = pd.DataFrame({'fd1': test_fd1_feature, \n",
    "                                  'fd2': test_fd2_feature, \n",
    "                                  'fd3': test_fd3_feature,\n",
    "                                  'fd4': test_fd4_feature, \n",
    "                                  'fd5': test_fd5_feature, \n",
    "                                  'fd6': test_fd6_feature,\n",
    "                                  'fd7': test_fd7_feature,\n",
    "                                  'what': test_what_feature, \n",
    "                                  'who': test_who_feature, \n",
    "                                  'why': test_why_feature,\n",
    "                                  'how': test_how_feature,\n",
    "                                  'length': test_length_feature,\n",
    "                                  'pos': test_pos_feature,\n",
    "                                  'numbers': test_numeric_feature})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb_predictions = nb_model.predict(df_test_features)\n",
    "test_set[\"category\"] = nb_predictions[test_set.index]\n",
    "output = test_set[['Id', 'category']]\n",
    "output.to_csv('../data/solution.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.3.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
